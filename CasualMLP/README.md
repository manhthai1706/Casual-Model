# CausalMLP v2.1

A complete causal discovery and inference framework combining **Causica/DECI** and **GraN-DAG** features with novel improvements.

M·ªôt framework kh√°m ph√° v√† suy lu·∫≠n nh√¢n qu·∫£ ho√†n ch·ªânh k·∫øt h·ª£p c√°c t√≠nh nƒÉng c·ªßa **Causica/DECI** v√† **GraN-DAG** v·ªõi nh·ªØng c·∫£i ti·∫øn m·ªõi.

## üåü Key Features / T√≠nh nƒÉng ch√≠nh

### Core Discovery / Kh√°m ph√° c·ªët l√µi
*   **Adjacency Learning**: ENCO, Soft Adjacency, and novel Dual-Head parameterization.
    *   H·ªçc ma tr·∫≠n k·ªÅ: ENCO, C·∫°nh m·ªÅm, v√† tham s·ªë h√≥a hai ƒë·∫ßu m·ªõi.
*   **Non-linear Relationships**: Efficient per-node MLPs with residuals and LayerNorm.
    *   M·ªëi quan h·ªá phi tuy·∫øn: MLP m·ªói n√∫t hi·ªáu qu·∫£ v·ªõi ph·∫ßn d∆∞ v√† chu·∫©n h√≥a l·ªõp.
*   **Graph Constraints**: GPU-accelerated NOTEARS constraint with Augmented Lagrangian.
    *   R√†ng bu·ªôc ƒë·ªì th·ªã: R√†ng bu·ªôc NOTEARS tƒÉng t·ªëc GPU v·ªõi Lagrangian tƒÉng c∆∞·ªùng.
*   **Noise Models**: Gaussian, Heteroscedastic, Adaptive, and Spline Flows.
    *   M√¥ h√¨nh nhi·ªÖu: Gaussian, D·ªã ph∆∞∆°ng sai, Th√≠ch ·ª©ng v√† Lu·ªìng Spline.

### Inference & Interventions / Suy lu·∫≠n & Can thi·ªáp
*   **Causal Inference**: `do()` calculus, ATE, CATE, ITE, and Counterfactuals.
    *   Suy lu·∫≠n nh√¢n qu·∫£: Ph√©p t√≠nh `do()`, ATE, CATE, ITE v√† Ph·∫£n th·ª±c t·∫ø.
*   **Neural CATE**: TARNet and DragonNet implementations.
    *   Neural CATE: Tri·ªÉn khai TARNet v√† DragonNet.
*   **Uncertainty**: Gumbel sampling for graph posteriors and bootstrapping.
    *   ƒê·ªô kh√¥ng ch·∫Øc ch·∫Øn: L·∫•y m·∫´u Gumbel cho h·∫≠u nghi·ªám ƒë·ªì th·ªã v√† bootstrapping.
*   **Active Learning**: Experimental design strategies for optimal interventions.
    *   H·ªçc ch·ªß ƒë·ªông: Chi·∫øn l∆∞·ª£c thi·∫øt k·∫ø th·ª≠ nghi·ªám cho c√°c can thi·ªáp t·ªëi ∆∞u.
*   **Variational Inference**: Bayesian posterior approximation.
    *   Suy lu·∫≠n bi·∫øn ph√¢n: X·∫•p x·ªâ h·∫≠u nghi·ªám Bayesian.

### Advanced Capabilities / Kh·∫£ nƒÉng n√¢ng cao
*   **Multi-Environment**: Learn from heterogeneous datasets (observational + interventional).
    *   ƒêa m√¥i tr∆∞·ªùng: H·ªçc t·ª´ c√°c t·∫≠p d·ªØ li·ªáu kh√¥ng ƒë·ªìng nh·∫•t (quan s√°t + can thi·ªáp).
*   **Latent Confounders**: Handling hidden variables via ADMGs.
    *   Bi·∫øn ·∫©n: X·ª≠ l√Ω c√°c bi·∫øn ·∫©n th√¥ng qua ADMG.
*   **Temporal Discovery**: Time-series causal modeling.
    *   Kh√°m ph√° theo th·ªùi gian: M√¥ h√¨nh h√≥a nh√¢n qu·∫£ chu·ªói th·ªùi gian.
*   **Missing Data**: Native handling of missing values.
    *   D·ªØ li·ªáu thi·∫øu: X·ª≠ l√Ω t·ª± nhi√™n c√°c gi√° tr·ªã b·ªã thi·∫øu.
*   **Embeddings**: Learnable node embeddings for transfer learning.
    *   Embeddings: C√°c embedding n√∫t c√≥ th·ªÉ h·ªçc ƒë∆∞·ª£c cho h·ªçc chuy·ªÉn ƒë·ªïi.

## üöÄ Quick Start / B·∫Øt ƒë·∫ßu nhanh

### Installation / C√†i ƒë·∫∑t

```bash
pip install -e .
```

### Basic Training / Hu·∫•n luy·ªán c∆° b·∫£n

```python
from config import CausalMLPConfig
from core import CausalMLPModel
from training import CurriculumTrainer

# Configure and train / C·∫•u h√¨nh v√† hu·∫•n luy·ªán
config = CausalMLPConfig.for_sachs()
model = CausalMLPModel(config)
trainer = CurriculumTrainer(model)
trainer.fit(data)

# Get the learned graph / L·∫•y ƒë·ªì th·ªã ƒë√£ h·ªçc
adj_matrix = model.get_adj()
```

### Interventions / Can thi·ªáp

```python
from inference import CausalInference

ci = CausalInference(model)
# Estimate ATE / ∆Ø·ªõc l∆∞·ª£ng ATE
ate = ci.ate(treatment_idx=0, outcome_idx=1)
print(f"ATE: {ate}")

# Counterfactual: What if node 0 had been 2.0?
# Ph·∫£n th·ª±c t·∫ø: ƒêi·ªÅu g√¨ x·∫£y ra n·∫øu n√∫t 0 l√† 2.0?
cf = ci.counterfactual(observation, {0: 2.0})
```

## üìÅ Project Structure / C·∫•u tr√∫c d·ª± √°n

*   `core/`: Main model components (MLP, Adjacency, Noise, Embeddings, Temporal, Multi-env).
    *   C√°c th√†nh ph·∫ßn m√¥ h√¨nh ch√≠nh.
*   `training/`: Training loops and curriculum strategies.
    *   V√≤ng l·∫∑p hu·∫•n luy·ªán v√† chi·∫øn l∆∞·ª£c ch∆∞∆°ng tr√¨nh.
*   `inference/`: Tools for interventions, uncertainty, and active learning.
    *   C√¥ng c·ª• cho can thi·ªáp, ƒë·ªô kh√¥ng ch·∫Øc ch·∫Øn v√† h·ªçc ch·ªß ƒë·ªông.
*   `utils/`: Metrics, pruning, visualization, and data handling.
    *   C√°c ch·ªâ s·ªë, c·∫Øt t·ªâa, tr·ª±c quan h√≥a v√† x·ª≠ l√Ω d·ªØ li·ªáu.

## üìÑ License

MIT License
